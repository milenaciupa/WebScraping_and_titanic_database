{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "689df44a",
   "metadata": {},
   "source": [
    "1. Z bazy danych znajdującej się w pliku data/sql/titanic.db, pobierz dane wszystkich osób, które przeżyły katastrofę Titanica i w czasie katastrofy miały powyżej 35 lat.\n",
    "2. Na stronie https://en.wikipedia.org/wiki/Passengers_of_the_Titanic znajdź wszystkie osoby, które przeżyły. Pobierz linki do stron Wikipedii o tych osobach.\n",
    "3. Połącz dane z naszej bazy danych z danymi pobranymi z Wikipedii. Interesują nas tylko osoby znajdujące się w obu zbiorach danych (ich nazwiska zostały zapisane w identyczny sposób w obu listach).\n",
    "\n",
    "## Dla każdej osoby:\n",
    "1. Otwórz stronę Wikipedii o tej osobie.\n",
    "2. Z prawej strony znajduje się prostokąt z podsumowaniem informacji o osobie. Pobierz z niego wszystkie dane.\n",
    "\n",
    "## Po pobraniu wszystkich osób:\n",
    "1. Zapisz dane z wikipedii i bazy danych w jednym pliku XLS. Dane o każdej osobie powinny znaleźć się w osobnej zakładce (nazwanej nazwiskiem i imieniem tej osoby).\n",
    "2. Każda zakładka powinna zawierać dwie kolumny: nazwa atrybutu i wartość (bez nagłówków i bez indeksu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b8fe3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "43506b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./titanic.db\"\n",
    "cnx = sqlite3.connect(file)\n",
    "query = \"\"\"SELECT * FROM passengers as p LEFT JOIN survivors as s ON p.PassengerId=s.PassengerId\n",
    "LEFT JOIN tickets as t ON p.PassengerId=t.PassengerId\n",
    "WHERE Survived=1 AND Age >35\"\"\"\n",
    "\n",
    "try:\n",
    "    titanic_df = pd.read_sql_query(query, cnx)\n",
    "    \n",
    "finally:\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "15b86f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "survivor_names = titanic_df['Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "df4159ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://en.wikipedia.org/wiki/Passengers_of_the_Titanic'\n",
    "\n",
    "response = requests.get(URL)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "html = soup.select('tr[style=\"background:#9bddff;\"] > td:first-child > a')\n",
    "\n",
    "people_urls = []\n",
    "\n",
    "for i in html:\n",
    "    links = i.text\n",
    "    if links in survivor_names:\n",
    "        people_urls.append((f\"https://en.wikipedia.org/{i['href']}\", links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "50297a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link, name in people_urls:\n",
    "    print(link, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c939a1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milen\\AppData\\Local\\Temp\\ipykernel_2288\\3592993630.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(soup.find_all('table', {'class': 'infobox'})))[0]\n",
      "C:\\Users\\milen\\AppData\\Local\\Temp\\ipykernel_2288\\3592993630.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(soup.find_all('table', {'class': 'infobox'})))[0]\n",
      "C:\\Users\\milen\\AppData\\Local\\Temp\\ipykernel_2288\\3592993630.py:8: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(soup.find_all('table', {'class': 'infobox'})))[0]\n"
     ]
    }
   ],
   "source": [
    "people_informations = []\n",
    "\n",
    "for link_name, name_people in people_urls:\n",
    "\n",
    "    response = requests.get(link_name)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    df = pd.read_html(str(soup.find_all('table', {'class': 'infobox'})))[0]\n",
    "    df.columns = ['Attribute', 'Value']\n",
    "    \n",
    "    data_from_db = titanic_df[titanic_df['Name'] == name_people].transpose().reset_index()\n",
    "    data_from_db.columns = ['Attribute', 'Value']\n",
    "    \n",
    "    \n",
    "    df = pd.concat([df, data_from_db])\n",
    "    df[df['Attribute'] != 'index']\n",
    "    people_informations.append((df, name_people))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "489d57a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('titanic.xlsx', engine='xlsxwriter' )\n",
    "\n",
    "for df, name in people_informations:\n",
    "    df.to_excel(writer, sheet_name=name, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
